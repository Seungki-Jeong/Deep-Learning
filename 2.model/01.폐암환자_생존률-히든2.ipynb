{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 폐암 수술 환자의 생존률 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 ,   2.8 ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,  12.  ,   0.  ,   0.  ,   0.  ,   1.  ,   0.  ,\n",
       "         62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88,   2.16,   1.  ,   0.  ,   0.  ,   0.  ,\n",
       "          1.  ,   1.  ,  14.  ,   0.  ,   0.  ,   0.  ,   1.  ,   0.  ,\n",
       "         60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19,   2.5 ,   1.  ,   0.  ,   0.  ,   0.  ,\n",
       "          1.  ,   0.  ,  11.  ,   0.  ,   0.  ,   1.  ,   1.  ,   0.  ,\n",
       "         66.  ,   1.  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = np.loadtxt(\"../data/ThoraricSurgery.csv\", delimiter = \",\")\n",
    "data_set[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((470, 17), (470,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_set[:, 0:17]\n",
    "Y = data_set[:, 17]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,181\n",
      "Trainable params: 1,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(30, input_shape = (17,), activation='relu'),\n",
    "    Dense(30, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 환경 설정(오차함수, 최적화함수)\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 76 samples\n",
      "Epoch 1/400\n",
      "300/300 [==============================] - 0s 1ms/sample - loss: 1.4934 - accuracy: 0.6433 - val_loss: 0.7813 - val_accuracy: 0.8947\n",
      "Epoch 2/400\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.9976 - accuracy: 0.8400 - val_loss: 0.3975 - val_accuracy: 0.8947\n",
      "Epoch 3/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.5242 - accuracy: 0.8100 - val_loss: 0.3644 - val_accuracy: 0.8816\n",
      "Epoch 4/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.5115 - accuracy: 0.8367 - val_loss: 0.3628 - val_accuracy: 0.8816\n",
      "Epoch 5/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4946 - accuracy: 0.8167 - val_loss: 0.3632 - val_accuracy: 0.8947\n",
      "Epoch 6/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.4673 - accuracy: 0.8400 - val_loss: 0.4494 - val_accuracy: 0.8816\n",
      "Epoch 7/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4544 - accuracy: 0.8367 - val_loss: 0.3477 - val_accuracy: 0.8947\n",
      "Epoch 8/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4533 - accuracy: 0.8367 - val_loss: 0.3567 - val_accuracy: 0.8947\n",
      "Epoch 9/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4542 - accuracy: 0.8333 - val_loss: 0.3501 - val_accuracy: 0.8947\n",
      "Epoch 10/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4584 - accuracy: 0.8400 - val_loss: 0.4584 - val_accuracy: 0.8816\n",
      "Epoch 11/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4933 - accuracy: 0.8333 - val_loss: 0.4337 - val_accuracy: 0.8947\n",
      "Epoch 12/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.5169 - accuracy: 0.8367 - val_loss: 0.3547 - val_accuracy: 0.8947\n",
      "Epoch 13/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.5017 - accuracy: 0.8400 - val_loss: 0.4624 - val_accuracy: 0.8947\n",
      "Epoch 14/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4860 - accuracy: 0.8400 - val_loss: 0.3623 - val_accuracy: 0.8947\n",
      "Epoch 15/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4415 - accuracy: 0.8367 - val_loss: 0.3496 - val_accuracy: 0.8947\n",
      "Epoch 16/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.76 - 0s 52us/sample - loss: 0.4328 - accuracy: 0.8400 - val_loss: 0.3570 - val_accuracy: 0.8947\n",
      "Epoch 17/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4446 - accuracy: 0.8400 - val_loss: 0.3453 - val_accuracy: 0.8947\n",
      "Epoch 18/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.4384 - accuracy: 0.8400 - val_loss: 0.3750 - val_accuracy: 0.8947\n",
      "Epoch 19/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.4339 - accuracy: 0.8433 - val_loss: 0.3593 - val_accuracy: 0.8947\n",
      "Epoch 20/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4373 - accuracy: 0.8433 - val_loss: 0.3503 - val_accuracy: 0.8947\n",
      "Epoch 21/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4382 - accuracy: 0.8433 - val_loss: 0.3496 - val_accuracy: 0.8947\n",
      "Epoch 22/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4337 - accuracy: 0.8433 - val_loss: 0.3723 - val_accuracy: 0.8947\n",
      "Epoch 23/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4429 - accuracy: 0.8400 - val_loss: 0.3519 - val_accuracy: 0.8947\n",
      "Epoch 24/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4434 - accuracy: 0.8433 - val_loss: 0.3508 - val_accuracy: 0.8947\n",
      "Epoch 25/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.4325 - accuracy: 0.8400 - val_loss: 0.3828 - val_accuracy: 0.8947\n",
      "Epoch 26/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4203 - accuracy: 0.8400 - val_loss: 0.3513 - val_accuracy: 0.8947\n",
      "Epoch 27/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4379 - accuracy: 0.8433 - val_loss: 0.3507 - val_accuracy: 0.8947\n",
      "Epoch 28/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4345 - accuracy: 0.8433 - val_loss: 0.4278 - val_accuracy: 0.8947\n",
      "Epoch 29/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4579 - accuracy: 0.8433 - val_loss: 0.3641 - val_accuracy: 0.8947\n",
      "Epoch 30/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4572 - accuracy: 0.8400 - val_loss: 0.3892 - val_accuracy: 0.8684\n",
      "Epoch 31/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4285 - accuracy: 0.8400 - val_loss: 0.3467 - val_accuracy: 0.8947\n",
      "Epoch 32/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4407 - accuracy: 0.8400 - val_loss: 0.3509 - val_accuracy: 0.8947\n",
      "Epoch 33/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4475 - accuracy: 0.8400 - val_loss: 0.3829 - val_accuracy: 0.8947\n",
      "Epoch 34/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.4354 - accuracy: 0.8433 - val_loss: 0.3532 - val_accuracy: 0.8947\n",
      "Epoch 35/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.4283 - accuracy: 0.8400 - val_loss: 0.3857 - val_accuracy: 0.8947\n",
      "Epoch 36/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4331 - accuracy: 0.8433 - val_loss: 0.3480 - val_accuracy: 0.8947\n",
      "Epoch 37/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.4252 - accuracy: 0.8400 - val_loss: 0.3666 - val_accuracy: 0.8947\n",
      "Epoch 38/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4396 - accuracy: 0.8433 - val_loss: 0.3875 - val_accuracy: 0.8947\n",
      "Epoch 39/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4508 - accuracy: 0.8433 - val_loss: 0.3580 - val_accuracy: 0.8947\n",
      "Epoch 40/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.5140 - accuracy: 0.8167 - val_loss: 0.3482 - val_accuracy: 0.8947\n",
      "Epoch 41/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.5522 - accuracy: 0.8400 - val_loss: 0.3901 - val_accuracy: 0.8684\n",
      "Epoch 42/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4832 - accuracy: 0.8400 - val_loss: 0.4177 - val_accuracy: 0.8816\n",
      "Epoch 43/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4508 - accuracy: 0.8433 - val_loss: 0.4166 - val_accuracy: 0.8947\n",
      "Epoch 44/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4604 - accuracy: 0.8300 - val_loss: 0.3600 - val_accuracy: 0.8947\n",
      "Epoch 45/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4375 - accuracy: 0.8400 - val_loss: 0.3482 - val_accuracy: 0.8947\n",
      "Epoch 46/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4407 - accuracy: 0.8433 - val_loss: 0.4713 - val_accuracy: 0.8553\n",
      "Epoch 47/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4374 - accuracy: 0.8400 - val_loss: 0.3374 - val_accuracy: 0.8947\n",
      "Epoch 48/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4283 - accuracy: 0.8433 - val_loss: 0.3454 - val_accuracy: 0.8947\n",
      "Epoch 49/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4506 - accuracy: 0.8433 - val_loss: 0.3435 - val_accuracy: 0.8947\n",
      "Epoch 50/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4859 - accuracy: 0.8400 - val_loss: 0.3920 - val_accuracy: 0.8684\n",
      "Epoch 51/400\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.4162 - accuracy: 0.8400 - val_loss: 0.3517 - val_accuracy: 0.8684\n",
      "Epoch 52/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4203 - accuracy: 0.8400 - val_loss: 0.4304 - val_accuracy: 0.8684\n",
      "Epoch 53/400\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.4434 - accuracy: 0.8433 - val_loss: 0.3548 - val_accuracy: 0.8947\n",
      "Epoch 54/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.4387 - accuracy: 0.8400 - val_loss: 0.3757 - val_accuracy: 0.8947\n",
      "Epoch 55/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4409 - accuracy: 0.8400 - val_loss: 0.3588 - val_accuracy: 0.8947\n",
      "Epoch 56/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4408 - accuracy: 0.8433 - val_loss: 0.3871 - val_accuracy: 0.8947\n",
      "Epoch 57/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.80 - 0s 60us/sample - loss: 0.4230 - accuracy: 0.8433 - val_loss: 0.3621 - val_accuracy: 0.8816\n",
      "Epoch 58/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4213 - accuracy: 0.8433 - val_loss: 0.3431 - val_accuracy: 0.8947\n",
      "Epoch 59/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4242 - accuracy: 0.8400 - val_loss: 0.3405 - val_accuracy: 0.8947\n",
      "Epoch 60/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4321 - accuracy: 0.8433 - val_loss: 0.3332 - val_accuracy: 0.8947\n",
      "Epoch 61/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4594 - accuracy: 0.8467 - val_loss: 0.5708 - val_accuracy: 0.7500\n",
      "Epoch 62/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4454 - accuracy: 0.8333 - val_loss: 0.3327 - val_accuracy: 0.8947\n",
      "Epoch 63/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4214 - accuracy: 0.8433 - val_loss: 0.3481 - val_accuracy: 0.8947\n",
      "Epoch 64/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4553 - accuracy: 0.8433 - val_loss: 0.3318 - val_accuracy: 0.8947\n",
      "Epoch 65/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4329 - accuracy: 0.8433 - val_loss: 0.3586 - val_accuracy: 0.8684\n",
      "Epoch 66/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4479 - accuracy: 0.8433 - val_loss: 0.4287 - val_accuracy: 0.8684\n",
      "Epoch 67/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4660 - accuracy: 0.8400 - val_loss: 0.4729 - val_accuracy: 0.8553\n",
      "Epoch 68/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4270 - accuracy: 0.8400 - val_loss: 0.3503 - val_accuracy: 0.8947\n",
      "Epoch 69/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5117 - accuracy: 0.76 - 0s 55us/sample - loss: 0.4284 - accuracy: 0.8433 - val_loss: 0.3384 - val_accuracy: 0.8947\n",
      "Epoch 70/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4239 - accuracy: 0.8433 - val_loss: 0.3415 - val_accuracy: 0.8947\n",
      "Epoch 71/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4255 - accuracy: 0.8433 - val_loss: 0.3331 - val_accuracy: 0.8947\n",
      "Epoch 72/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4236 - accuracy: 0.8433 - val_loss: 0.3330 - val_accuracy: 0.8947\n",
      "Epoch 73/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4411 - accuracy: 0.8400 - val_loss: 0.3509 - val_accuracy: 0.8947\n",
      "Epoch 74/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4558 - accuracy: 0.8433 - val_loss: 0.3351 - val_accuracy: 0.8947\n",
      "Epoch 75/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4483 - accuracy: 0.8433 - val_loss: 0.3508 - val_accuracy: 0.8684\n",
      "Epoch 76/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4412 - accuracy: 0.8467 - val_loss: 0.3763 - val_accuracy: 0.8684\n",
      "Epoch 77/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4370 - accuracy: 0.8433 - val_loss: 0.4089 - val_accuracy: 0.8947\n",
      "Epoch 78/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4590 - accuracy: 0.8433 - val_loss: 0.4255 - val_accuracy: 0.8553\n",
      "Epoch 79/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4914 - accuracy: 0.8367 - val_loss: 0.4046 - val_accuracy: 0.8816\n",
      "Epoch 80/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.6308 - accuracy: 0.7667 - val_loss: 0.4824 - val_accuracy: 0.8684\n",
      "Epoch 81/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.5489 - accuracy: 0.8167 - val_loss: 0.3679 - val_accuracy: 0.8947\n",
      "Epoch 82/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.5486 - accuracy: 0.8200 - val_loss: 0.5039 - val_accuracy: 0.8684\n",
      "Epoch 83/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4539 - accuracy: 0.8433 - val_loss: 0.3507 - val_accuracy: 0.8947\n",
      "Epoch 84/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4117 - accuracy: 0.8433 - val_loss: 0.3321 - val_accuracy: 0.8947\n",
      "Epoch 85/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4194 - accuracy: 0.8400 - val_loss: 0.3853 - val_accuracy: 0.8947\n",
      "Epoch 86/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4102 - accuracy: 0.8433 - val_loss: 0.3422 - val_accuracy: 0.8684\n",
      "Epoch 87/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4110 - accuracy: 0.8400 - val_loss: 0.3844 - val_accuracy: 0.8684\n",
      "Epoch 88/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4211 - accuracy: 0.8433 - val_loss: 0.3232 - val_accuracy: 0.8947\n",
      "Epoch 89/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4196 - accuracy: 0.8433 - val_loss: 0.3364 - val_accuracy: 0.8947\n",
      "Epoch 90/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4469 - accuracy: 0.8433 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 91/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4291 - accuracy: 0.8433 - val_loss: 0.3342 - val_accuracy: 0.8947\n",
      "Epoch 92/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4258 - accuracy: 0.8433 - val_loss: 0.3600 - val_accuracy: 0.8947\n",
      "Epoch 93/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4281 - accuracy: 0.8367 - val_loss: 0.3594 - val_accuracy: 0.8684\n",
      "Epoch 94/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4052 - accuracy: 0.8433 - val_loss: 0.3535 - val_accuracy: 0.8947\n",
      "Epoch 95/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4147 - accuracy: 0.8467 - val_loss: 0.3588 - val_accuracy: 0.8816\n",
      "Epoch 96/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4100 - accuracy: 0.8433 - val_loss: 0.3363 - val_accuracy: 0.8947\n",
      "Epoch 97/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4156 - accuracy: 0.8433 - val_loss: 0.3298 - val_accuracy: 0.8947\n",
      "Epoch 98/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4134 - accuracy: 0.8433 - val_loss: 0.3485 - val_accuracy: 0.8947\n",
      "Epoch 99/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4359 - accuracy: 0.8433 - val_loss: 0.3633 - val_accuracy: 0.8684\n",
      "Epoch 100/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4133 - accuracy: 0.8400 - val_loss: 0.3569 - val_accuracy: 0.8816\n",
      "Epoch 101/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4379 - accuracy: 0.8433 - val_loss: 0.3241 - val_accuracy: 0.8947\n",
      "Epoch 102/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4057 - accuracy: 0.8467 - val_loss: 0.3823 - val_accuracy: 0.8816\n",
      "Epoch 103/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4141 - accuracy: 0.8433 - val_loss: 0.3500 - val_accuracy: 0.8947\n",
      "Epoch 104/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4134 - accuracy: 0.8433 - val_loss: 0.3614 - val_accuracy: 0.8947\n",
      "Epoch 105/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4034 - accuracy: 0.8400 - val_loss: 0.3582 - val_accuracy: 0.8684\n",
      "Epoch 106/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4185 - accuracy: 0.8433 - val_loss: 0.3317 - val_accuracy: 0.8947\n",
      "Epoch 107/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4215 - accuracy: 0.8400 - val_loss: 0.3347 - val_accuracy: 0.8947\n",
      "Epoch 108/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4581 - accuracy: 0.8433 - val_loss: 0.3579 - val_accuracy: 0.8684\n",
      "Epoch 109/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.4233 - accuracy: 0.8467 - val_loss: 0.3780 - val_accuracy: 0.8816\n",
      "Epoch 110/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.4087 - accuracy: 0.8467 - val_loss: 0.3391 - val_accuracy: 0.8947\n",
      "Epoch 111/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4231 - accuracy: 0.8467 - val_loss: 0.3444 - val_accuracy: 0.8947\n",
      "Epoch 112/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4597 - accuracy: 0.8467 - val_loss: 0.3316 - val_accuracy: 0.8947\n",
      "Epoch 113/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4103 - accuracy: 0.8433 - val_loss: 0.3363 - val_accuracy: 0.8947\n",
      "Epoch 114/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4248 - accuracy: 0.8433 - val_loss: 0.3625 - val_accuracy: 0.9079\n",
      "Epoch 115/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.4037 - accuracy: 0.8467 - val_loss: 0.3643 - val_accuracy: 0.8816\n",
      "Epoch 116/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.4390 - accuracy: 0.8467 - val_loss: 0.3509 - val_accuracy: 0.8947\n",
      "Epoch 117/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4300 - accuracy: 0.8367 - val_loss: 0.3297 - val_accuracy: 0.8947\n",
      "Epoch 118/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4113 - accuracy: 0.8433 - val_loss: 0.3294 - val_accuracy: 0.8947\n",
      "Epoch 119/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3989 - accuracy: 0.8433 - val_loss: 0.3479 - val_accuracy: 0.8684\n",
      "Epoch 120/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4074 - accuracy: 0.8400 - val_loss: 0.3216 - val_accuracy: 0.8947\n",
      "Epoch 121/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3955 - accuracy: 0.8433 - val_loss: 0.3725 - val_accuracy: 0.8816\n",
      "Epoch 122/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4159 - accuracy: 0.8433 - val_loss: 0.3300 - val_accuracy: 0.8947\n",
      "Epoch 123/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4051 - accuracy: 0.8467 - val_loss: 0.3171 - val_accuracy: 0.8947\n",
      "Epoch 124/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4044 - accuracy: 0.8467 - val_loss: 0.3408 - val_accuracy: 0.8816\n",
      "Epoch 125/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3983 - accuracy: 0.8433 - val_loss: 0.4247 - val_accuracy: 0.8684\n",
      "Epoch 126/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.4032 - accuracy: 0.8433 - val_loss: 0.3214 - val_accuracy: 0.8947\n",
      "Epoch 127/400\n",
      "300/300 [==============================] - 0s 62us/sample - loss: 0.4105 - accuracy: 0.8433 - val_loss: 0.3391 - val_accuracy: 0.8947\n",
      "Epoch 128/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4188 - accuracy: 0.8433 - val_loss: 0.3765 - val_accuracy: 0.8816\n",
      "Epoch 129/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3961 - accuracy: 0.8433 - val_loss: 0.3340 - val_accuracy: 0.8947\n",
      "Epoch 130/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3994 - accuracy: 0.8433 - val_loss: 0.3221 - val_accuracy: 0.8947\n",
      "Epoch 131/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4165 - accuracy: 0.8433 - val_loss: 0.3513 - val_accuracy: 0.9079\n",
      "Epoch 132/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3984 - accuracy: 0.8467 - val_loss: 0.3410 - val_accuracy: 0.9079\n",
      "Epoch 133/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4107 - accuracy: 0.8533 - val_loss: 0.3282 - val_accuracy: 0.8947\n",
      "Epoch 134/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4013 - accuracy: 0.8433 - val_loss: 0.3337 - val_accuracy: 0.8947\n",
      "Epoch 135/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3918 - accuracy: 0.8400 - val_loss: 0.3344 - val_accuracy: 0.8816\n",
      "Epoch 136/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4030 - accuracy: 0.8433 - val_loss: 0.3389 - val_accuracy: 0.8684\n",
      "Epoch 137/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4570 - accuracy: 0.8433 - val_loss: 0.3306 - val_accuracy: 0.8947\n",
      "Epoch 138/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.4483 - accuracy: 0.8467 - val_loss: 0.3189 - val_accuracy: 0.8947\n",
      "Epoch 139/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.4112 - accuracy: 0.8400 - val_loss: 0.3340 - val_accuracy: 0.8816\n",
      "Epoch 140/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4083 - accuracy: 0.8567 - val_loss: 0.3427 - val_accuracy: 0.8947\n",
      "Epoch 141/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4687 - accuracy: 0.8500 - val_loss: 0.3534 - val_accuracy: 0.8947\n",
      "Epoch 142/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4275 - accuracy: 0.8367 - val_loss: 0.3947 - val_accuracy: 0.8684\n",
      "Epoch 143/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.4121 - accuracy: 0.8433 - val_loss: 0.4291 - val_accuracy: 0.8684\n",
      "Epoch 144/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4103 - accuracy: 0.8400 - val_loss: 0.3321 - val_accuracy: 0.8816\n",
      "Epoch 145/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3953 - accuracy: 0.8400 - val_loss: 0.3547 - val_accuracy: 0.8816\n",
      "Epoch 146/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4085 - accuracy: 0.8400 - val_loss: 0.3142 - val_accuracy: 0.8947\n",
      "Epoch 147/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4257 - accuracy: 0.8400 - val_loss: 0.3933 - val_accuracy: 0.8684\n",
      "Epoch 148/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4040 - accuracy: 0.8433 - val_loss: 0.3924 - val_accuracy: 0.8816\n",
      "Epoch 149/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4899 - accuracy: 0.8100 - val_loss: 0.3549 - val_accuracy: 0.8947\n",
      "Epoch 150/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4621 - accuracy: 0.8433 - val_loss: 0.3261 - val_accuracy: 0.8947\n",
      "Epoch 151/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4320 - accuracy: 0.8400 - val_loss: 0.3198 - val_accuracy: 0.8947\n",
      "Epoch 152/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4063 - accuracy: 0.8500 - val_loss: 0.3341 - val_accuracy: 0.8816\n",
      "Epoch 153/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3975 - accuracy: 0.8500 - val_loss: 0.3113 - val_accuracy: 0.8947\n",
      "Epoch 154/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3822 - accuracy: 0.8400 - val_loss: 0.4077 - val_accuracy: 0.8553\n",
      "Epoch 155/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3801 - accuracy: 0.8533 - val_loss: 0.3217 - val_accuracy: 0.8947\n",
      "Epoch 156/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4396 - accuracy: 0.8400 - val_loss: 0.3928 - val_accuracy: 0.8684\n",
      "Epoch 157/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4455 - accuracy: 0.8400 - val_loss: 0.4114 - val_accuracy: 0.8816\n",
      "Epoch 158/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4632 - accuracy: 0.8433 - val_loss: 0.3131 - val_accuracy: 0.8947\n",
      "Epoch 159/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4082 - accuracy: 0.8367 - val_loss: 0.3934 - val_accuracy: 0.8947\n",
      "Epoch 160/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4883 - accuracy: 0.8367 - val_loss: 0.3361 - val_accuracy: 0.8816\n",
      "Epoch 161/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4562 - accuracy: 0.8467 - val_loss: 0.4987 - val_accuracy: 0.8158\n",
      "Epoch 162/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.3247 - val_accuracy: 0.9079\n",
      "Epoch 163/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4043 - accuracy: 0.8500 - val_loss: 0.3278 - val_accuracy: 0.8947\n",
      "Epoch 164/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3927 - accuracy: 0.8467 - val_loss: 0.3416 - val_accuracy: 0.9079\n",
      "Epoch 165/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4179 - accuracy: 0.8433 - val_loss: 0.4037 - val_accuracy: 0.8553\n",
      "Epoch 166/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4310 - accuracy: 0.8467 - val_loss: 0.3715 - val_accuracy: 0.8816\n",
      "Epoch 167/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4098 - accuracy: 0.8467 - val_loss: 0.4425 - val_accuracy: 0.8684\n",
      "Epoch 168/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4132 - accuracy: 0.8567 - val_loss: 0.3299 - val_accuracy: 0.9079\n",
      "Epoch 169/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3872 - accuracy: 0.8533 - val_loss: 0.3295 - val_accuracy: 0.8816\n",
      "Epoch 170/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4037 - accuracy: 0.8500 - val_loss: 0.3227 - val_accuracy: 0.8947\n",
      "Epoch 171/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3979 - accuracy: 0.8533 - val_loss: 0.3588 - val_accuracy: 0.8816\n",
      "Epoch 172/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4042 - accuracy: 0.8433 - val_loss: 0.3374 - val_accuracy: 0.8816\n",
      "Epoch 173/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3940 - accuracy: 0.8433 - val_loss: 0.3249 - val_accuracy: 0.9079\n",
      "Epoch 174/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.4034 - accuracy: 0.8500 - val_loss: 0.3185 - val_accuracy: 0.9079\n",
      "Epoch 175/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4070 - accuracy: 0.8500 - val_loss: 0.3206 - val_accuracy: 0.9079\n",
      "Epoch 176/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.4088 - accuracy: 0.8500 - val_loss: 0.3237 - val_accuracy: 0.9079\n",
      "Epoch 177/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.90 - 0s 53us/sample - loss: 0.4031 - accuracy: 0.8533 - val_loss: 0.3248 - val_accuracy: 0.9079\n",
      "Epoch 178/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3860 - accuracy: 0.8433 - val_loss: 0.3878 - val_accuracy: 0.8553\n",
      "Epoch 179/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3946 - accuracy: 0.8467 - val_loss: 0.3539 - val_accuracy: 0.8947\n",
      "Epoch 180/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3900 - accuracy: 0.8567 - val_loss: 0.3200 - val_accuracy: 0.9079\n",
      "Epoch 181/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.4027 - accuracy: 0.8500 - val_loss: 0.3460 - val_accuracy: 0.8684\n",
      "Epoch 182/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3851 - accuracy: 0.8500 - val_loss: 0.3629 - val_accuracy: 0.8816\n",
      "Epoch 183/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3764 - accuracy: 0.8500 - val_loss: 0.3200 - val_accuracy: 0.9079\n",
      "Epoch 184/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3922 - accuracy: 0.8433 - val_loss: 0.3393 - val_accuracy: 0.8816\n",
      "Epoch 185/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3960 - accuracy: 0.8500 - val_loss: 0.3199 - val_accuracy: 0.8947\n",
      "Epoch 186/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4161 - accuracy: 0.8100 - val_loss: 0.3242 - val_accuracy: 0.8947\n",
      "Epoch 187/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4196 - accuracy: 0.8500 - val_loss: 0.3857 - val_accuracy: 0.8553\n",
      "Epoch 188/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3992 - accuracy: 0.8567 - val_loss: 0.3354 - val_accuracy: 0.8947\n",
      "Epoch 189/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3943 - accuracy: 0.8533 - val_loss: 0.3436 - val_accuracy: 0.8947\n",
      "Epoch 190/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3899 - accuracy: 0.8467 - val_loss: 0.3925 - val_accuracy: 0.8421\n",
      "Epoch 191/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4002 - accuracy: 0.8533 - val_loss: 0.3797 - val_accuracy: 0.8816\n",
      "Epoch 192/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3825 - accuracy: 0.8533 - val_loss: 0.3320 - val_accuracy: 0.8816\n",
      "Epoch 193/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4361 - accuracy: 0.8433 - val_loss: 0.3185 - val_accuracy: 0.8947\n",
      "Epoch 194/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4062 - accuracy: 0.8500 - val_loss: 0.3352 - val_accuracy: 0.8947\n",
      "Epoch 195/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4120 - accuracy: 0.8500 - val_loss: 0.4435 - val_accuracy: 0.8553\n",
      "Epoch 196/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4300 - accuracy: 0.8533 - val_loss: 0.3828 - val_accuracy: 0.8684\n",
      "Epoch 197/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3990 - accuracy: 0.8500 - val_loss: 0.3657 - val_accuracy: 0.8816\n",
      "Epoch 198/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3866 - accuracy: 0.8533 - val_loss: 0.3220 - val_accuracy: 0.9079\n",
      "Epoch 199/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.3786 - accuracy: 0.8467 - val_loss: 0.3747 - val_accuracy: 0.8684\n",
      "Epoch 200/400\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.4185 - accuracy: 0.8467 - val_loss: 0.4093 - val_accuracy: 0.8684\n",
      "Epoch 201/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3934 - accuracy: 0.8533 - val_loss: 0.3777 - val_accuracy: 0.8816\n",
      "Epoch 202/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3855 - accuracy: 0.8567 - val_loss: 0.3280 - val_accuracy: 0.9079\n",
      "Epoch 203/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.4123 - accuracy: 0.8567 - val_loss: 0.3243 - val_accuracy: 0.8947\n",
      "Epoch 204/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.76 - 0s 58us/sample - loss: 0.4175 - accuracy: 0.8467 - val_loss: 0.3161 - val_accuracy: 0.9079\n",
      "Epoch 205/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.80 - 0s 57us/sample - loss: 0.3909 - accuracy: 0.8500 - val_loss: 0.3163 - val_accuracy: 0.9079\n",
      "Epoch 206/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3922 - accuracy: 0.8533 - val_loss: 0.3119 - val_accuracy: 0.9079\n",
      "Epoch 207/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3792 - accuracy: 0.8567 - val_loss: 0.3148 - val_accuracy: 0.9079\n",
      "Epoch 208/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3990 - accuracy: 0.8400 - val_loss: 0.3285 - val_accuracy: 0.8816\n",
      "Epoch 209/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4434 - accuracy: 0.8433 - val_loss: 0.5565 - val_accuracy: 0.6974\n",
      "Epoch 210/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.5391 - accuracy: 0.8133 - val_loss: 0.3314 - val_accuracy: 0.8947\n",
      "Epoch 211/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3902 - accuracy: 0.8433 - val_loss: 0.3129 - val_accuracy: 0.9079\n",
      "Epoch 212/400\n",
      "300/300 [==============================] - 0s 61us/sample - loss: 0.3796 - accuracy: 0.8533 - val_loss: 0.3801 - val_accuracy: 0.8553\n",
      "Epoch 213/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4476 - accuracy: 0.8233 - val_loss: 0.3791 - val_accuracy: 0.8947\n",
      "Epoch 214/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4508 - accuracy: 0.8300 - val_loss: 0.3063 - val_accuracy: 0.9079\n",
      "Epoch 215/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4269 - accuracy: 0.8467 - val_loss: 0.3755 - val_accuracy: 0.8816\n",
      "Epoch 216/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4171 - accuracy: 0.8533 - val_loss: 0.4296 - val_accuracy: 0.8553\n",
      "Epoch 217/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4335 - accuracy: 0.8500 - val_loss: 0.3431 - val_accuracy: 0.8553\n",
      "Epoch 218/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3768 - accuracy: 0.8533 - val_loss: 0.3374 - val_accuracy: 0.8816\n",
      "Epoch 219/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.3729 - accuracy: 0.8533 - val_loss: 0.3489 - val_accuracy: 0.8684\n",
      "Epoch 220/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3783 - accuracy: 0.8533 - val_loss: 0.3584 - val_accuracy: 0.8553\n",
      "Epoch 221/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3661 - accuracy: 0.8567 - val_loss: 0.3111 - val_accuracy: 0.9079\n",
      "Epoch 222/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3751 - accuracy: 0.8533 - val_loss: 0.3241 - val_accuracy: 0.8947\n",
      "Epoch 223/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3837 - accuracy: 0.8533 - val_loss: 0.3228 - val_accuracy: 0.9079\n",
      "Epoch 224/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.86 - 0s 54us/sample - loss: 0.3829 - accuracy: 0.8467 - val_loss: 0.3950 - val_accuracy: 0.8684\n",
      "Epoch 225/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3907 - accuracy: 0.8467 - val_loss: 0.3793 - val_accuracy: 0.8553\n",
      "Epoch 226/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3806 - accuracy: 0.8600 - val_loss: 0.3496 - val_accuracy: 0.8553\n",
      "Epoch 227/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3793 - accuracy: 0.8533 - val_loss: 0.3193 - val_accuracy: 0.9079\n",
      "Epoch 228/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3806 - accuracy: 0.8567 - val_loss: 0.3297 - val_accuracy: 0.8816\n",
      "Epoch 229/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4114 - accuracy: 0.8400 - val_loss: 0.4495 - val_accuracy: 0.8553\n",
      "Epoch 230/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4138 - accuracy: 0.8500 - val_loss: 0.3384 - val_accuracy: 0.8684\n",
      "Epoch 231/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3803 - accuracy: 0.8467 - val_loss: 0.3898 - val_accuracy: 0.8816\n",
      "Epoch 232/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3893 - accuracy: 0.8567 - val_loss: 0.3302 - val_accuracy: 0.8816\n",
      "Epoch 233/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3786 - accuracy: 0.8533 - val_loss: 0.3741 - val_accuracy: 0.8553\n",
      "Epoch 234/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3820 - accuracy: 0.8500 - val_loss: 0.3244 - val_accuracy: 0.8947\n",
      "Epoch 235/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3672 - accuracy: 0.8533 - val_loss: 0.3457 - val_accuracy: 0.8553\n",
      "Epoch 236/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3690 - accuracy: 0.8600 - val_loss: 0.3139 - val_accuracy: 0.9079\n",
      "Epoch 237/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3744 - accuracy: 0.8600 - val_loss: 0.3253 - val_accuracy: 0.8947\n",
      "Epoch 238/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3741 - accuracy: 0.8500 - val_loss: 0.4104 - val_accuracy: 0.8421\n",
      "Epoch 239/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3900 - accuracy: 0.8500 - val_loss: 0.3361 - val_accuracy: 0.8553\n",
      "Epoch 240/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.3908 - accuracy: 0.8500 - val_loss: 0.3194 - val_accuracy: 0.8947\n",
      "Epoch 241/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3874 - accuracy: 0.8433 - val_loss: 0.3639 - val_accuracy: 0.9079\n",
      "Epoch 242/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.5021 - accuracy: 0.7967 - val_loss: 0.3052 - val_accuracy: 0.9079\n",
      "Epoch 243/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.5034 - accuracy: 0.8500 - val_loss: 0.3983 - val_accuracy: 0.8289\n",
      "Epoch 244/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4335 - accuracy: 0.8500 - val_loss: 0.3354 - val_accuracy: 0.9079\n",
      "Epoch 245/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3858 - accuracy: 0.8567 - val_loss: 0.3144 - val_accuracy: 0.9079\n",
      "Epoch 246/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3873 - accuracy: 0.8500 - val_loss: 0.3307 - val_accuracy: 0.8816\n",
      "Epoch 247/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.3954 - accuracy: 0.8567 - val_loss: 0.3137 - val_accuracy: 0.9079\n",
      "Epoch 248/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.4111 - accuracy: 0.8500 - val_loss: 0.3374 - val_accuracy: 0.8553\n",
      "Epoch 249/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.3729 - accuracy: 0.8500 - val_loss: 0.3779 - val_accuracy: 0.8947\n",
      "Epoch 250/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3906 - accuracy: 0.8567 - val_loss: 0.3816 - val_accuracy: 0.8421\n",
      "Epoch 251/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3989 - accuracy: 0.8567 - val_loss: 0.3353 - val_accuracy: 0.8816\n",
      "Epoch 252/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3732 - accuracy: 0.8500 - val_loss: 0.3261 - val_accuracy: 0.8684\n",
      "Epoch 253/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3808 - accuracy: 0.8433 - val_loss: 0.3179 - val_accuracy: 0.9079\n",
      "Epoch 254/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3817 - accuracy: 0.8600 - val_loss: 0.3314 - val_accuracy: 0.8816\n",
      "Epoch 255/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3690 - accuracy: 0.8567 - val_loss: 0.3395 - val_accuracy: 0.8684\n",
      "Epoch 256/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3768 - accuracy: 0.8500 - val_loss: 0.3738 - val_accuracy: 0.8421\n",
      "Epoch 257/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3681 - accuracy: 0.8467 - val_loss: 0.3130 - val_accuracy: 0.8947\n",
      "Epoch 258/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3722 - accuracy: 0.8600 - val_loss: 0.3141 - val_accuracy: 0.9079\n",
      "Epoch 259/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.86 - 0s 56us/sample - loss: 0.3696 - accuracy: 0.8567 - val_loss: 0.3575 - val_accuracy: 0.8684\n",
      "Epoch 260/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3714 - accuracy: 0.8567 - val_loss: 0.3118 - val_accuracy: 0.9079\n",
      "Epoch 261/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.93 - 0s 58us/sample - loss: 0.3736 - accuracy: 0.8600 - val_loss: 0.3214 - val_accuracy: 0.8816\n",
      "Epoch 262/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3689 - accuracy: 0.8600 - val_loss: 0.3242 - val_accuracy: 0.8947\n",
      "Epoch 263/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3651 - accuracy: 0.8500 - val_loss: 0.3150 - val_accuracy: 0.9079\n",
      "Epoch 264/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3973 - accuracy: 0.8533 - val_loss: 0.3099 - val_accuracy: 0.9079\n",
      "Epoch 265/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4045 - accuracy: 0.8567 - val_loss: 0.4235 - val_accuracy: 0.8026\n",
      "Epoch 266/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.3812 - accuracy: 0.8467 - val_loss: 0.3319 - val_accuracy: 0.8816\n",
      "Epoch 267/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3810 - accuracy: 0.8433 - val_loss: 0.3090 - val_accuracy: 0.8947\n",
      "Epoch 268/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3795 - accuracy: 0.8600 - val_loss: 0.3148 - val_accuracy: 0.9079\n",
      "Epoch 269/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3793 - accuracy: 0.8633 - val_loss: 0.3217 - val_accuracy: 0.9079\n",
      "Epoch 270/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3986 - accuracy: 0.8567 - val_loss: 0.3289 - val_accuracy: 0.8553\n",
      "Epoch 271/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3777 - accuracy: 0.8533 - val_loss: 0.3436 - val_accuracy: 0.8553\n",
      "Epoch 272/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3665 - accuracy: 0.8633 - val_loss: 0.3122 - val_accuracy: 0.9079\n",
      "Epoch 273/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3608 - accuracy: 0.8567 - val_loss: 0.3459 - val_accuracy: 0.8816\n",
      "Epoch 274/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3637 - accuracy: 0.8667 - val_loss: 0.3272 - val_accuracy: 0.8816\n",
      "Epoch 275/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3755 - accuracy: 0.8567 - val_loss: 0.3139 - val_accuracy: 0.9079\n",
      "Epoch 276/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3887 - accuracy: 0.8367 - val_loss: 0.3616 - val_accuracy: 0.8553\n",
      "Epoch 277/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3669 - accuracy: 0.8633 - val_loss: 0.3446 - val_accuracy: 0.8684\n",
      "Epoch 278/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3740 - accuracy: 0.8500 - val_loss: 0.3165 - val_accuracy: 0.9079\n",
      "Epoch 279/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4237 - accuracy: 0.8433 - val_loss: 0.3135 - val_accuracy: 0.9079\n",
      "Epoch 280/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3753 - accuracy: 0.8567 - val_loss: 0.3131 - val_accuracy: 0.8947\n",
      "Epoch 281/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3737 - accuracy: 0.8567 - val_loss: 0.3274 - val_accuracy: 0.8947\n",
      "Epoch 282/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3635 - accuracy: 0.8567 - val_loss: 0.3865 - val_accuracy: 0.8947\n",
      "Epoch 283/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3807 - accuracy: 0.8600 - val_loss: 0.4017 - val_accuracy: 0.8816\n",
      "Epoch 284/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3546 - accuracy: 0.8467 - val_loss: 0.3137 - val_accuracy: 0.9079\n",
      "Epoch 285/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5409 - accuracy: 0.83 - 0s 55us/sample - loss: 0.4099 - accuracy: 0.8367 - val_loss: 0.3520 - val_accuracy: 0.8947\n",
      "Epoch 286/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.5022 - accuracy: 0.8467 - val_loss: 0.5722 - val_accuracy: 0.6579\n",
      "Epoch 287/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.4336 - accuracy: 0.8333 - val_loss: 0.3324 - val_accuracy: 0.8684\n",
      "Epoch 288/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3761 - accuracy: 0.8600 - val_loss: 0.3152 - val_accuracy: 0.9079\n",
      "Epoch 289/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.3912 - accuracy: 0.8500 - val_loss: 0.3242 - val_accuracy: 0.9079\n",
      "Epoch 290/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3811 - accuracy: 0.8367 - val_loss: 0.3688 - val_accuracy: 0.8684\n",
      "Epoch 291/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3745 - accuracy: 0.8567 - val_loss: 0.3357 - val_accuracy: 0.8816\n",
      "Epoch 292/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.90 - 0s 57us/sample - loss: 0.3670 - accuracy: 0.8500 - val_loss: 0.3297 - val_accuracy: 0.8553\n",
      "Epoch 293/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3616 - accuracy: 0.8367 - val_loss: 0.3091 - val_accuracy: 0.9079\n",
      "Epoch 294/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3919 - accuracy: 0.8533 - val_loss: 0.3124 - val_accuracy: 0.8947\n",
      "Epoch 295/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.4086 - accuracy: 0.8567 - val_loss: 0.4702 - val_accuracy: 0.7632\n",
      "Epoch 296/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4135 - accuracy: 0.8433 - val_loss: 0.3912 - val_accuracy: 0.8816\n",
      "Epoch 297/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.3825 - accuracy: 0.8467 - val_loss: 0.3728 - val_accuracy: 0.8421\n",
      "Epoch 298/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3704 - accuracy: 0.8567 - val_loss: 0.3175 - val_accuracy: 0.8816\n",
      "Epoch 299/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3657 - accuracy: 0.8600 - val_loss: 0.3088 - val_accuracy: 0.9079\n",
      "Epoch 300/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4034 - accuracy: 0.8500 - val_loss: 0.3279 - val_accuracy: 0.9079\n",
      "Epoch 301/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4716 - accuracy: 0.8400 - val_loss: 0.4339 - val_accuracy: 0.8158\n",
      "Epoch 302/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3597 - accuracy: 0.8500 - val_loss: 0.3260 - val_accuracy: 0.8816\n",
      "Epoch 303/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3546 - accuracy: 0.8567 - val_loss: 0.3093 - val_accuracy: 0.9079\n",
      "Epoch 304/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.3593 - accuracy: 0.8600 - val_loss: 0.3513 - val_accuracy: 0.8684\n",
      "Epoch 305/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3809 - accuracy: 0.8633 - val_loss: 0.3310 - val_accuracy: 0.8816\n",
      "Epoch 306/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3616 - accuracy: 0.8600 - val_loss: 0.3949 - val_accuracy: 0.8684\n",
      "Epoch 307/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3650 - accuracy: 0.8433 - val_loss: 0.3286 - val_accuracy: 0.8553\n",
      "Epoch 308/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3615 - accuracy: 0.8600 - val_loss: 0.3534 - val_accuracy: 0.8947\n",
      "Epoch 309/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3564 - accuracy: 0.8533 - val_loss: 0.3485 - val_accuracy: 0.8289\n",
      "Epoch 310/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3814 - accuracy: 0.8500 - val_loss: 0.3455 - val_accuracy: 0.8816\n",
      "Epoch 311/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3781 - accuracy: 0.8600 - val_loss: 0.3504 - val_accuracy: 0.8421\n",
      "Epoch 312/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3693 - accuracy: 0.8567 - val_loss: 0.3700 - val_accuracy: 0.8947\n",
      "Epoch 313/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3578 - accuracy: 0.8633 - val_loss: 0.3174 - val_accuracy: 0.9079\n",
      "Epoch 314/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3763 - accuracy: 0.8433 - val_loss: 0.3199 - val_accuracy: 0.8947\n",
      "Epoch 315/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.3746 - accuracy: 0.8600 - val_loss: 0.3422 - val_accuracy: 0.8816\n",
      "Epoch 316/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3954 - accuracy: 0.8567 - val_loss: 0.4336 - val_accuracy: 0.8684\n",
      "Epoch 317/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3774 - accuracy: 0.8567 - val_loss: 0.3388 - val_accuracy: 0.8553\n",
      "Epoch 318/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3574 - accuracy: 0.8500 - val_loss: 0.3169 - val_accuracy: 0.9079\n",
      "Epoch 319/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3611 - accuracy: 0.8700 - val_loss: 0.3596 - val_accuracy: 0.8947\n",
      "Epoch 320/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3599 - accuracy: 0.8633 - val_loss: 0.3615 - val_accuracy: 0.8816\n",
      "Epoch 321/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3626 - accuracy: 0.8633 - val_loss: 0.3405 - val_accuracy: 0.8684\n",
      "Epoch 322/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3780 - accuracy: 0.8633 - val_loss: 0.3145 - val_accuracy: 0.9079\n",
      "Epoch 323/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.3769 - accuracy: 0.8533 - val_loss: 0.3151 - val_accuracy: 0.8947\n",
      "Epoch 324/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3678 - accuracy: 0.8467 - val_loss: 0.3004 - val_accuracy: 0.9079\n",
      "Epoch 325/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3559 - accuracy: 0.8667 - val_loss: 0.3285 - val_accuracy: 0.8684\n",
      "Epoch 326/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3533 - accuracy: 0.8600 - val_loss: 0.3474 - val_accuracy: 0.8684\n",
      "Epoch 327/400\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.3545 - accuracy: 0.8667 - val_loss: 0.3445 - val_accuracy: 0.8421\n",
      "Epoch 328/400\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.3572 - accuracy: 0.8600 - val_loss: 0.3182 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3486 - accuracy: 0.8600 - val_loss: 0.3073 - val_accuracy: 0.8816\n",
      "Epoch 330/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3708 - accuracy: 0.8467 - val_loss: 0.3360 - val_accuracy: 0.8684\n",
      "Epoch 331/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3647 - accuracy: 0.8567 - val_loss: 0.3400 - val_accuracy: 0.8816\n",
      "Epoch 332/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.3481 - accuracy: 0.8567 - val_loss: 0.3229 - val_accuracy: 0.8684\n",
      "Epoch 333/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3709 - accuracy: 0.8533 - val_loss: 0.3202 - val_accuracy: 0.9079\n",
      "Epoch 334/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.4026 - accuracy: 0.8500 - val_loss: 0.3209 - val_accuracy: 0.8816\n",
      "Epoch 335/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3644 - accuracy: 0.8567 - val_loss: 0.3102 - val_accuracy: 0.8947\n",
      "Epoch 336/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3631 - accuracy: 0.8533 - val_loss: 0.3279 - val_accuracy: 0.8816\n",
      "Epoch 337/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3413 - accuracy: 0.8567 - val_loss: 0.3409 - val_accuracy: 0.8947\n",
      "Epoch 338/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.4055 - accuracy: 0.8600 - val_loss: 0.3080 - val_accuracy: 0.8816\n",
      "Epoch 339/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3774 - accuracy: 0.8600 - val_loss: 0.3416 - val_accuracy: 0.8816\n",
      "Epoch 340/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3738 - accuracy: 0.8600 - val_loss: 0.4077 - val_accuracy: 0.8421\n",
      "Epoch 341/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3707 - accuracy: 0.8533 - val_loss: 0.3790 - val_accuracy: 0.8816\n",
      "Epoch 342/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3655 - accuracy: 0.8567 - val_loss: 0.3427 - val_accuracy: 0.8553\n",
      "Epoch 343/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3672 - accuracy: 0.8633 - val_loss: 0.4384 - val_accuracy: 0.8553\n",
      "Epoch 344/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3678 - accuracy: 0.8500 - val_loss: 0.3301 - val_accuracy: 0.8553\n",
      "Epoch 345/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3543 - accuracy: 0.8633 - val_loss: 0.3623 - val_accuracy: 0.8816\n",
      "Epoch 346/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3511 - accuracy: 0.8600 - val_loss: 0.3623 - val_accuracy: 0.8816\n",
      "Epoch 347/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3762 - accuracy: 0.8567 - val_loss: 0.4798 - val_accuracy: 0.7895\n",
      "Epoch 348/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3775 - accuracy: 0.8500 - val_loss: 0.3258 - val_accuracy: 0.8816\n",
      "Epoch 349/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.76 - 0s 56us/sample - loss: 0.3522 - accuracy: 0.8633 - val_loss: 0.3139 - val_accuracy: 0.8816\n",
      "Epoch 350/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3539 - accuracy: 0.8467 - val_loss: 0.3082 - val_accuracy: 0.8947\n",
      "Epoch 351/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3478 - accuracy: 0.8600 - val_loss: 0.3568 - val_accuracy: 0.8684\n",
      "Epoch 352/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3730 - accuracy: 0.8700 - val_loss: 0.4810 - val_accuracy: 0.7763\n",
      "Epoch 353/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4275 - accuracy: 0.8500 - val_loss: 0.4457 - val_accuracy: 0.8289\n",
      "Epoch 354/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.4303 - accuracy: 0.8367 - val_loss: 0.3140 - val_accuracy: 0.9079\n",
      "Epoch 355/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3651 - accuracy: 0.8533 - val_loss: 0.3060 - val_accuracy: 0.9079\n",
      "Epoch 356/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3670 - accuracy: 0.8633 - val_loss: 0.3261 - val_accuracy: 0.8684\n",
      "Epoch 357/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3457 - accuracy: 0.8633 - val_loss: 0.4083 - val_accuracy: 0.8421\n",
      "Epoch 358/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3789 - accuracy: 0.8600 - val_loss: 0.3183 - val_accuracy: 0.9079\n",
      "Epoch 359/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3644 - accuracy: 0.8500 - val_loss: 0.3412 - val_accuracy: 0.8947\n",
      "Epoch 360/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3439 - accuracy: 0.8533 - val_loss: 0.3222 - val_accuracy: 0.8684\n",
      "Epoch 361/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.3475 - accuracy: 0.8567 - val_loss: 0.3134 - val_accuracy: 0.8947\n",
      "Epoch 362/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3437 - accuracy: 0.8667 - val_loss: 0.3667 - val_accuracy: 0.8816\n",
      "Epoch 363/400\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.3433 - accuracy: 0.8667 - val_loss: 0.3438 - val_accuracy: 0.8553\n",
      "Epoch 364/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3453 - accuracy: 0.8567 - val_loss: 0.3122 - val_accuracy: 0.8816\n",
      "Epoch 365/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.3464 - accuracy: 0.8600 - val_loss: 0.3112 - val_accuracy: 0.8947\n",
      "Epoch 366/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.3758 - accuracy: 0.8667 - val_loss: 0.3296 - val_accuracy: 0.8553\n",
      "Epoch 367/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3591 - accuracy: 0.8633 - val_loss: 0.3241 - val_accuracy: 0.8816\n",
      "Epoch 368/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3552 - accuracy: 0.8533 - val_loss: 0.3182 - val_accuracy: 0.8816\n",
      "Epoch 369/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3666 - accuracy: 0.8600 - val_loss: 0.3047 - val_accuracy: 0.8816\n",
      "Epoch 370/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3763 - accuracy: 0.8633 - val_loss: 0.3821 - val_accuracy: 0.8553\n",
      "Epoch 371/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3448 - accuracy: 0.8633 - val_loss: 0.3258 - val_accuracy: 0.8816\n",
      "Epoch 372/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.3492 - accuracy: 0.8633 - val_loss: 0.3416 - val_accuracy: 0.8684\n",
      "Epoch 373/400\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3591 - accuracy: 0.8600 - val_loss: 0.3442 - val_accuracy: 0.8816\n",
      "Epoch 374/400\n",
      "300/300 [==============================] - 0s 51us/sample - loss: 0.3663 - accuracy: 0.8567 - val_loss: 0.4034 - val_accuracy: 0.8553\n",
      "Epoch 375/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3453 - accuracy: 0.8567 - val_loss: 0.3311 - val_accuracy: 0.8684\n",
      "Epoch 376/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3487 - accuracy: 0.8567 - val_loss: 0.3380 - val_accuracy: 0.8684\n",
      "Epoch 377/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3488 - accuracy: 0.8567 - val_loss: 0.3151 - val_accuracy: 0.8947\n",
      "Epoch 378/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3717 - accuracy: 0.8667 - val_loss: 0.3161 - val_accuracy: 0.9079\n",
      "Epoch 379/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3571 - accuracy: 0.8567 - val_loss: 0.3447 - val_accuracy: 0.8684\n",
      "Epoch 380/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3593 - accuracy: 0.8500 - val_loss: 0.3048 - val_accuracy: 0.8816\n",
      "Epoch 381/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3559 - accuracy: 0.8567 - val_loss: 0.3114 - val_accuracy: 0.8816\n",
      "Epoch 382/400\n",
      "300/300 [==============================] - 0s 52us/sample - loss: 0.3593 - accuracy: 0.8600 - val_loss: 0.3063 - val_accuracy: 0.8947\n",
      "Epoch 383/400\n",
      "300/300 [==============================] - 0s 54us/sample - loss: 0.3710 - accuracy: 0.8533 - val_loss: 0.3383 - val_accuracy: 0.8684\n",
      "Epoch 384/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3394 - accuracy: 0.8633 - val_loss: 0.3105 - val_accuracy: 0.8947\n",
      "Epoch 385/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3608 - accuracy: 0.8600 - val_loss: 0.3194 - val_accuracy: 0.8816\n",
      "Epoch 386/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3481 - accuracy: 0.8567 - val_loss: 0.3091 - val_accuracy: 0.8684\n",
      "Epoch 387/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3460 - accuracy: 0.8633 - val_loss: 0.3425 - val_accuracy: 0.8816\n",
      "Epoch 388/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.76 - 0s 57us/sample - loss: 0.3334 - accuracy: 0.8633 - val_loss: 0.3106 - val_accuracy: 0.8816\n",
      "Epoch 389/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3532 - accuracy: 0.8567 - val_loss: 0.3202 - val_accuracy: 0.8684\n",
      "Epoch 390/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3531 - accuracy: 0.8600 - val_loss: 0.3144 - val_accuracy: 0.8684\n",
      "Epoch 391/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3760 - accuracy: 0.8600 - val_loss: 0.5942 - val_accuracy: 0.6579\n",
      "Epoch 392/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3845 - accuracy: 0.8467 - val_loss: 0.3046 - val_accuracy: 0.8947\n",
      "Epoch 393/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3583 - accuracy: 0.8600 - val_loss: 0.3502 - val_accuracy: 0.9079\n",
      "Epoch 394/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.4786 - accuracy: 0.8600 - val_loss: 0.3504 - val_accuracy: 0.8553\n",
      "Epoch 395/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.96 - 0s 58us/sample - loss: 0.3827 - accuracy: 0.8567 - val_loss: 0.3934 - val_accuracy: 0.8684\n",
      "Epoch 396/400\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.3647 - accuracy: 0.8433 - val_loss: 0.3345 - val_accuracy: 0.8816\n",
      "Epoch 397/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3457 - accuracy: 0.8667 - val_loss: 0.3355 - val_accuracy: 0.8684\n",
      "Epoch 398/400\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.3366 - accuracy: 0.8633 - val_loss: 0.3318 - val_accuracy: 0.8816\n",
      "Epoch 399/400\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.3481 - accuracy: 0.8600 - val_loss: 0.3119 - val_accuracy: 0.8947\n",
      "Epoch 400/400\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.3548 - accuracy: 0.8600 - val_loss: 0.3196 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 학습\n",
    "# Validation set의 비율을 20%\n",
    "history = model.fit(X_train, y_train, validation_split = 0.2, epochs = 400, batch_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 0s - loss: 0.7396 - accuracy: 0.7979\n",
      "\n",
      " Accuracy: 0.7979\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\"%(model.evaluate(X_test, y_test, verbose=2))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.493390</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.781285</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.397472</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.524184</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.364403</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511506</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494555</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.363237</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.364657</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.334473</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.345679</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.336604</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.331760</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.348085</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.311914</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.354796</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.319613</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.493390  0.643333  0.781285      0.894737\n",
       "1    0.997625  0.840000  0.397472      0.894737\n",
       "2    0.524184  0.810000  0.364403      0.881579\n",
       "3    0.511506  0.836667  0.362823      0.881579\n",
       "4    0.494555  0.816667  0.363237      0.894737\n",
       "..        ...       ...       ...           ...\n",
       "395  0.364657  0.843333  0.334473      0.881579\n",
       "396  0.345679  0.866667  0.335541      0.868421\n",
       "397  0.336604  0.863333  0.331760      0.881579\n",
       "398  0.348085  0.860000  0.311914      0.894737\n",
       "399  0.354796  0.860000  0.319613      0.868421\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(history.history)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
