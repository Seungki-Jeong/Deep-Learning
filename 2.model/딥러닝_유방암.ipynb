{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유방암"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2진 분류\n",
    "- 베스트 모델 저장\n",
    "- 자동 중단\n",
    "- 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1984      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 4,737\n",
      "Trainable params: 4,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape = (30,), activation = 'relu'),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(16, activation = 'relu'),\n",
    "    Dense(8, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + \"final{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer_callback = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 13.42468, saving model to ./model/final001-13.4247.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 13.42468 to 11.80958, saving model to ./model/final002-11.8096.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 11.80958 to 10.28355, saving model to ./model/final003-10.2836.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 10.28355 to 8.91331, saving model to ./model/final004-8.9133.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.91331 to 7.82251, saving model to ./model/final005-7.8225.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 7.82251 to 6.86362, saving model to ./model/final006-6.8636.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.86362 to 5.97820, saving model to ./model/final007-5.9782.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.97820 to 5.15335, saving model to ./model/final008-5.1533.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 5.15335 to 4.38392, saving model to ./model/final009-4.3839.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.38392 to 3.68026, saving model to ./model/final010-3.6803.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.68026 to 3.03093, saving model to ./model/final011-3.0309.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.03093 to 2.43369, saving model to ./model/final012-2.4337.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.43369 to 1.90465, saving model to ./model/final013-1.9047.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.90465 to 1.50864, saving model to ./model/final014-1.5086.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.50864 to 1.28021, saving model to ./model/final015-1.2802.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.28021 to 1.06952, saving model to ./model/final016-1.0695.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.06952 to 0.95542, saving model to ./model/final017-0.9554.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.95542 to 0.87447, saving model to ./model/final018-0.8745.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.87447 to 0.80264, saving model to ./model/final019-0.8026.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.80264 to 0.72659, saving model to ./model/final020-0.7266.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.72659 to 0.66101, saving model to ./model/final021-0.6610.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.66101 to 0.64566, saving model to ./model/final022-0.6457.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.64566\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.64566\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.64566\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.64566\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.64566\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.64566 to 0.63882, saving model to ./model/final028-0.6388.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.63882 to 0.62164, saving model to ./model/final029-0.6216.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.62164 to 0.61302, saving model to ./model/final030-0.6130.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.61302 to 0.61066, saving model to ./model/final031-0.6107.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.61066 to 0.61056, saving model to ./model/final032-0.6106.hdf5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.61056\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.61056 to 0.60860, saving model to ./model/final041-0.6086.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.60860 to 0.60618, saving model to ./model/final042-0.6062.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.60618 to 0.60588, saving model to ./model/final043-0.6059.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.60588\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.60588 to 0.60487, saving model to ./model/final064-0.6049.hdf5\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.60487 to 0.60362, saving model to ./model/final065-0.6036.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.60362 to 0.60265, saving model to ./model/final066-0.6027.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.60265 to 0.60198, saving model to ./model/final067-0.6020.hdf5\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.60198 to 0.60097, saving model to ./model/final068-0.6010.hdf5\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.60097 to 0.59920, saving model to ./model/final069-0.5992.hdf5\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.59920 to 0.59784, saving model to ./model/final070-0.5978.hdf5\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.59784 to 0.59724, saving model to ./model/final071-0.5972.hdf5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.59724\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.59724\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.59724\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.59724\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.59724\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.59724 to 0.59576, saving model to ./model/final077-0.5958.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.59576 to 0.59082, saving model to ./model/final078-0.5908.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.59082 to 0.58199, saving model to ./model/final079-0.5820.hdf5\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.58199 to 0.57139, saving model to ./model/final080-0.5714.hdf5\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.57139 to 0.56438, saving model to ./model/final081-0.5644.hdf5\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.56438 to 0.55979, saving model to ./model/final082-0.5598.hdf5\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.55979\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.55979\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.55979\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.55979\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.55979\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.55979\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.55979\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.55979 to 0.55550, saving model to ./model/final090-0.5555.hdf5\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.55550 to 0.54338, saving model to ./model/final091-0.5434.hdf5\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.54338 to 0.52969, saving model to ./model/final092-0.5297.hdf5\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.52969 to 0.52125, saving model to ./model/final093-0.5212.hdf5\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.52125 to 0.51679, saving model to ./model/final094-0.5168.hdf5\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.51679 to 0.51522, saving model to ./model/final095-0.5152.hdf5\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.51522\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.51522\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.51522\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.51522 to 0.51429, saving model to ./model/final099-0.5143.hdf5\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.51429 to 0.50498, saving model to ./model/final100-0.5050.hdf5\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.50498 to 0.49291, saving model to ./model/final101-0.4929.hdf5\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.49291 to 0.48023, saving model to ./model/final102-0.4802.hdf5\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.48023 to 0.46728, saving model to ./model/final103-0.4673.hdf5\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.46728 to 0.45676, saving model to ./model/final104-0.4568.hdf5\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.45676 to 0.45120, saving model to ./model/final105-0.4512.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00106: val_loss improved from 0.45120 to 0.44910, saving model to ./model/final106-0.4491.hdf5\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.44910 to 0.44876, saving model to ./model/final107-0.4488.hdf5\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.44876 to 0.44584, saving model to ./model/final108-0.4458.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.44584 to 0.43696, saving model to ./model/final109-0.4370.hdf5\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.43696 to 0.42505, saving model to ./model/final110-0.4251.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.42505 to 0.41217, saving model to ./model/final111-0.4122.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.41217 to 0.40099, saving model to ./model/final112-0.4010.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.40099 to 0.39096, saving model to ./model/final113-0.3910.hdf5\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.39096 to 0.38238, saving model to ./model/final114-0.3824.hdf5\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.38238 to 0.37620, saving model to ./model/final115-0.3762.hdf5\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.37620 to 0.37246, saving model to ./model/final116-0.3725.hdf5\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.37246 to 0.36928, saving model to ./model/final117-0.3693.hdf5\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.36928 to 0.36507, saving model to ./model/final118-0.3651.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.36507 to 0.35912, saving model to ./model/final119-0.3591.hdf5\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.35912 to 0.35136, saving model to ./model/final120-0.3514.hdf5\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.35136 to 0.34345, saving model to ./model/final121-0.3434.hdf5\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.34345 to 0.33545, saving model to ./model/final122-0.3355.hdf5\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.33545 to 0.32779, saving model to ./model/final123-0.3278.hdf5\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.32779 to 0.32123, saving model to ./model/final124-0.3212.hdf5\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.32123 to 0.31665, saving model to ./model/final125-0.3167.hdf5\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.31665 to 0.31397, saving model to ./model/final126-0.3140.hdf5\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.31397 to 0.31294, saving model to ./model/final127-0.3129.hdf5\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.31294 to 0.31262, saving model to ./model/final128-0.3126.hdf5\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.31262 to 0.31101, saving model to ./model/final129-0.3110.hdf5\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.31101 to 0.30777, saving model to ./model/final130-0.3078.hdf5\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.30777 to 0.30279, saving model to ./model/final131-0.3028.hdf5\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.30279 to 0.29689, saving model to ./model/final132-0.2969.hdf5\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.29689 to 0.29180, saving model to ./model/final133-0.2918.hdf5\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.29180 to 0.28913, saving model to ./model/final134-0.2891.hdf5\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.28913 to 0.28863, saving model to ./model/final135-0.2886.hdf5\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.28863 to 0.28847, saving model to ./model/final136-0.2885.hdf5\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.28847 to 0.28821, saving model to ./model/final137-0.2882.hdf5\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.28821 to 0.28802, saving model to ./model/final138-0.2880.hdf5\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.28802 to 0.28619, saving model to ./model/final139-0.2862.hdf5\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.28619 to 0.28292, saving model to ./model/final140-0.2829.hdf5\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.28292 to 0.27942, saving model to ./model/final141-0.2794.hdf5\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.27942 to 0.27723, saving model to ./model/final142-0.2772.hdf5\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.27723 to 0.27623, saving model to ./model/final143-0.2762.hdf5\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.27623 to 0.27619, saving model to ./model/final144-0.2762.hdf5\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.27619 to 0.27591, saving model to ./model/final145-0.2759.hdf5\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.27591 to 0.27484, saving model to ./model/final146-0.2748.hdf5\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.27484 to 0.27297, saving model to ./model/final147-0.2730.hdf5\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.27297 to 0.27076, saving model to ./model/final148-0.2708.hdf5\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.27076 to 0.26859, saving model to ./model/final149-0.2686.hdf5\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.26859 to 0.26693, saving model to ./model/final150-0.2669.hdf5\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.26693 to 0.26633, saving model to ./model/final151-0.2663.hdf5\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.26633\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.26633\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.26633\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.26633 to 0.26611, saving model to ./model/final155-0.2661.hdf5\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.26611 to 0.26500, saving model to ./model/final156-0.2650.hdf5\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.26500 to 0.26435, saving model to ./model/final157-0.2643.hdf5\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.26435 to 0.26341, saving model to ./model/final162-0.2634.hdf5\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.26341 to 0.26257, saving model to ./model/final163-0.2626.hdf5\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.26257 to 0.26257, saving model to ./model/final164-0.2626.hdf5\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.26257\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.26257\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.26257\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.26257 to 0.26227, saving model to ./model/final168-0.2623.hdf5\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.26227 to 0.26134, saving model to ./model/final169-0.2613.hdf5\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.26134\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.26134\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.26134\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.26134\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.26134\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.26134 to 0.26108, saving model to ./model/final175-0.2611.hdf5\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.26108 to 0.26102, saving model to ./model/final176-0.2610.hdf5\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.26102\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.26102\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.26102\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.26102 to 0.26082, saving model to ./model/final180-0.2608.hdf5\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.26082 to 0.26043, saving model to ./model/final181-0.2604.hdf5\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.26043 to 0.26032, saving model to ./model/final182-0.2603.hdf5\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.26032\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.26032\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.26032\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.26032\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.26032\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.26032 to 0.25929, saving model to ./model/final188-0.2593.hdf5\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.25929 to 0.25836, saving model to ./model/final189-0.2584.hdf5\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.25836 to 0.25836, saving model to ./model/final190-0.2584.hdf5\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.25836\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.25836\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.25836\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.25836 to 0.25769, saving model to ./model/final194-0.2577.hdf5\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.25769 to 0.25725, saving model to ./model/final195-0.2572.hdf5\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.25725\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.25725 to 0.25668, saving model to ./model/final208-0.2567.hdf5\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.25668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00210: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.25668\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.25668 to 0.25511, saving model to ./model/final258-0.2551.hdf5\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.25511 to 0.25425, saving model to ./model/final259-0.2542.hdf5\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.25425\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.25425\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.25425 to 0.25402, saving model to ./model/final262-0.2540.hdf5\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.25402 to 0.25326, saving model to ./model/final263-0.2533.hdf5\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.25326\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.25326 to 0.25195, saving model to ./model/final281-0.2520.hdf5\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.25195 to 0.25154, saving model to ./model/final282-0.2515.hdf5\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.25154 to 0.25149, saving model to ./model/final283-0.2515.hdf5\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.25149\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.25149\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.25149 to 0.25092, saving model to ./model/final286-0.2509.hdf5\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.25092 to 0.24892, saving model to ./model/final287-0.2489.hdf5\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.24892 to 0.24879, saving model to ./model/final288-0.2488.hdf5\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.24879\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.24879\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.24879\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.24879 to 0.24853, saving model to ./model/final292-0.2485.hdf5\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.24853 to 0.24456, saving model to ./model/final293-0.2446.hdf5\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.24456 to 0.24238, saving model to ./model/final294-0.2424.hdf5\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.24238\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.24238\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.24238\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.24238 to 0.24140, saving model to ./model/final298-0.2414.hdf5\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.24140 to 0.24026, saving model to ./model/final299-0.2403.hdf5\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.24026\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.24026\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.24026\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.24026 to 0.23914, saving model to ./model/final303-0.2391.hdf5\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.23914 to 0.23869, saving model to ./model/final304-0.2387.hdf5\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.23869\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.23869 to 0.23799, saving model to ./model/final320-0.2380.hdf5\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.23799\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.23799\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.23799\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.23799 to 0.23792, saving model to ./model/final324-0.2379.hdf5\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.23792 to 0.23775, saving model to ./model/final325-0.2377.hdf5\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.23775\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.23775\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.23775 to 0.23681, saving model to ./model/final328-0.2368.hdf5\n",
      "\n",
      "Epoch 00329: val_loss improved from 0.23681 to 0.23500, saving model to ./model/final329-0.2350.hdf5\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.23500\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.23500\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.23500 to 0.23359, saving model to ./model/final332-0.2336.hdf5\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.23359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00348: val_loss did not improve from 0.23359\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.23359 to 0.23169, saving model to ./model/final349-0.2317.hdf5\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.23169\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.23169\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.23169 to 0.22992, saving model to ./model/final352-0.2299.hdf5\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.22992 to 0.22968, saving model to ./model/final360-0.2297.hdf5\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.22968\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.22968\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.22968 to 0.22817, saving model to ./model/final363-0.2282.hdf5\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.22817\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.22817\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.22817\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.22817 to 0.22695, saving model to ./model/final367-0.2270.hdf5\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.22695\n",
      "\n",
      "Epoch 00399: val_loss improved from 0.22695 to 0.22339, saving model to ./model/final399-0.2234.hdf5\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.22339\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.22339\n",
      "\n",
      "Epoch 00402: val_loss improved from 0.22339 to 0.22160, saving model to ./model/final402-0.2216.hdf5\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.22160\n",
      "\n",
      "Epoch 00418: val_loss improved from 0.22160 to 0.21819, saving model to ./model/final418-0.2182.hdf5\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.21819\n",
      "\n",
      "Epoch 00428: val_loss improved from 0.21819 to 0.21686, saving model to ./model/final428-0.2169.hdf5\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.21686\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.21686\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.21686 to 0.21476, saving model to ./model/final431-0.2148.hdf5\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.21476\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.21476 to 0.21446, saving model to ./model/final441-0.2145.hdf5\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.21446\n",
      "\n",
      "Epoch 00470: val_loss improved from 0.21446 to 0.21392, saving model to ./model/final470-0.2139.hdf5\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.21392\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.21392\n",
      "\n",
      "Epoch 00473: val_loss improved from 0.21392 to 0.21363, saving model to ./model/final473-0.2136.hdf5\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.21363\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.21363\n",
      "\n",
      "Epoch 00476: val_loss improved from 0.21363 to 0.21110, saving model to ./model/final476-0.2111.hdf5\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.21110\n",
      "\n",
      "Epoch 00504: val_loss improved from 0.21110 to 0.20823, saving model to ./model/final504-0.2082.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00505: val_loss did not improve from 0.20823\n",
      "\n",
      "Epoch 00506: val_loss improved from 0.20823 to 0.20593, saving model to ./model/final506-0.2059.hdf5\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.20593\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.20593\n",
      "\n",
      "Epoch 00509: val_loss improved from 0.20593 to 0.20530, saving model to ./model/final509-0.2053.hdf5\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.20530\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.20530\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.20530\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.20530\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.20530\n",
      "\n",
      "Epoch 00515: val_loss improved from 0.20530 to 0.20473, saving model to ./model/final515-0.2047.hdf5\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.20473\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.20473\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.20473\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.20473\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.20473\n",
      "\n",
      "Epoch 00521: val_loss improved from 0.20473 to 0.20109, saving model to ./model/final521-0.2011.hdf5\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.20109\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.20109\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.20109\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.20109\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.20109\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.20109\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.20109\n",
      "\n",
      "Epoch 00529: val_loss improved from 0.20109 to 0.19808, saving model to ./model/final529-0.1981.hdf5\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.19808\n",
      "\n",
      "Epoch 00553: val_loss improved from 0.19808 to 0.19576, saving model to ./model/final553-0.1958.hdf5\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.19576\n",
      "\n",
      "Epoch 00593: val_loss improved from 0.19576 to 0.19093, saving model to ./model/final593-0.1909.hdf5\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.19093\n",
      "\n",
      "Epoch 00595: val_loss improved from 0.19093 to 0.17715, saving model to ./model/final595-0.1771.hdf5\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.17715\n",
      "\n",
      "Epoch 00597: val_loss improved from 0.17715 to 0.17497, saving model to ./model/final597-0.1750.hdf5\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.17497\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.17497\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.17497\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.17497\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.17497\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.17497\n",
      "\n",
      "Epoch 00604: val_loss improved from 0.17497 to 0.17307, saving model to ./model/final604-0.1731.hdf5\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.17307\n",
      "\n",
      "Epoch 00662: val_loss improved from 0.17307 to 0.15558, saving model to ./model/final662-0.1556.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00663: val_loss did not improve from 0.15558\n",
      "\n",
      "Epoch 00664: val_loss improved from 0.15558 to 0.13772, saving model to ./model/final664-0.1377.hdf5\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.13772\n",
      "\n",
      "Epoch 00746: val_loss improved from 0.13772 to 0.12301, saving model to ./model/final746-0.1230.hdf5\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.12301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00836: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.12301\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.12301\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model/final746-0.1230.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 - 0s - loss: 0.0930 - accuracy: 0.9561\n",
      "\n",
      " Accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_vloss=history.history['val_loss']\n",
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.ylim((0, 1))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
